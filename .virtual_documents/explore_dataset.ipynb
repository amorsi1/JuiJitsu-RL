import numpy as np
import pandas as pd
import os
import re



# Read the data from the file
with open('GrappleMap.txt', 'r') as file:
    data = file.read()

# Split the data into individual entries
entries = data.strip().split('\n\n')

# Create a list to store the parsed data
table_data = []

# Parse each entry
for entry in entries:
    # Split the entry into title, tags, and content
    parts = entry.strip().split('\n', 2)
    
    if len(parts) == 3:
        title, tags, content = parts
        # Extract the tags
        tags = tags.replace('tags:', '').strip().split()
        
        # Add the parsed data to the table
        table_data.append({'Title': title, 'Tags': ', '.join(tags), 'Content': content.strip()})
    else:
        print(f"Skipping invalid entry: {entry}")

# Create a DataFrame from the parsed data
df = pd.DataFrame(table_data)

# Print the DataFrame
print(df)


df.head()


import pandas as pd
import re

def parse_file(file_path):
    with open(file_path, 'r') as file:
        content = file.read()

    # Split the content into individual entries
    entries = re.split(r'\n(?=[a-zA-Z])', content)

    data = []
    for entry in entries:
        lines = entry.strip().split('\n')
        
        # Extract title
        title = ' '.join(line for line in lines if not line.startswith('tags:') and not line.startswith('ref:') and not line.strip().startswith('Q') and not line.strip().startswith('n') and not line.strip().startswith('v') and not line.strip().startswith('x') and not line.strip().startswith('B') and not line.strip().startswith('A') and not line.strip().startswith('C') and not line.strip().startswith('D') and not line.strip().startswith('E') and not line.strip().startswith('F') and not line.strip().startswith('G') and not line.strip().startswith('H') and not line.strip().startswith('I') and not line.strip().startswith('J') and not line.strip().startswith('K') and not line.strip().startswith('L') and not line.strip().startswith('M') and not line.strip().startswith('N') and not line.strip().startswith('O') and not line.strip().startswith('P') and not line.strip().startswith('R') and not line.strip().startswith('S') and not line.strip().startswith('T') and not line.strip().startswith('U') and not line.strip().startswith('V') and not line.strip().startswith('W') and not line.strip().startswith('X') and not line.strip().startswith('Y') and not line.strip().startswith('Z'))
        
        # Extract tags
        tags = next((line.replace('tags:', '').strip() for line in lines if line.startswith('tags:')), '')
        
        # Extract encoded data
        encoded_data = ' '.join(line.strip() for line in lines if line.strip() and not line.startswith('tags:') and not line.startswith('ref:') and line.strip()[0].isupper())
        
        data.append({
            'Title': title.strip(),
            'Tags': tags,
            'Encoded_Data': encoded_data
        })

    return pd.DataFrame(data)

# Use the function
df = parse_file('GrappleMap.txt')

# Display the first few rows of the DataFrame
print(df.head())

# Save the DataFrame to a CSV file
df.to_csv('bjj_techniques.csv', index=False)


def preprocess_file(input_file, output_file):
    with open(input_file, 'r') as file:
        content = file.read()

    lines = content.split('\n')
    filtered_lines = [line for line in lines if not line.startswith('ref:') or not line.startswith('todo:')]

    filtered_content = '\n'.join(filtered_lines)

    with open(output_file, 'w') as file:
        file.write(filtered_content)

# Usage example
input_file = 'GrappleMap.txt'
output_file = 'GrappleMap_processed.txt'
preprocess_file(input_file, output_file)


import pandas as pd

def parse_file(file_path):
    with open(file_path, 'r') as file:
        content = file.read()

    techniques = []
    blocks = content.split('\ntags:')
    for block in blocks[1:]:  # Skip the first block which is empty
        lines = block.strip().split('\n')
        if len(lines) >= 3:
            name = lines[0].strip()
            tags = lines[1].strip()#.split()[0]  # Get the first word after 'tags:'
            data = '\n'.join(lines[2:]).strip()
            techniques.append({'name': name, 'tags': tags, 'data': data})

    df = pd.DataFrame(techniques)
    return df

# Usage example
file_path = 'GrappleMap_processed.txt'
df = parse_file(file_path)
print(df)


# import hashlib

# filename = 'GrappleMap.txt'
# with open(fname, 'rb') as ff:
#     db = ff.read().decode('utf-8')
#     dbhash = hashlib.md5(db.encode('utf-8')).hexdigest()
#     indexFile = filename + ".index"
#     connections = []
#     print(db)


def preprocess_file(file_path):
    filename, file_ext = os.path.splitext(file_path)
    with open(file_path, 'rb') as ff:
        db = ff.read().decode('utf-8')
        # dbhash = hashlib.md5(db.encode('utf-8')).hexdigest()
        # indexFile = filename + ".index"
        # connections = []
        # print(db)
        lines = db.split('\n')
        filtered_lines = [line for line in lines if not line.startswith('ref:') and not line.startswith('todo')] #one instance where todo is added without a : after it

        filtered_content = '\n'.join(filtered_lines)
        with open(filename+'_processed'+file_ext, 'w') as file:
            file.write(filtered_content)
preprocess_file("GrappleMap.txt")


# def test_base64(line):
#     try: 
#         base64.b64decode(line.encode())
#         return True
#     except (base64.binascii.Error, UnicodeDecodeError):
#         # If the decoding fails, the line doesn't contain valid 64-bit data
#         return False
        

def process_block_recursive(lines, description=''):
    print(len(lines))
    # pattern_64bit = r'^[a-zA-Z0-9+/]{64}$'
    
    result = {
        'description': description,
        'properties': '',
        'tags': '',
        'code': []
    }
    
    for idx, line in enumerate(lines):
        if line.startswith('properties:'):
            result['properties'] = line.split(':', 1)[1].strip()
        elif line.startswith('tags:'):
            result['tags'] = line.split(':', 1)[1].strip()
        elif len(line.strip()) == 69: #and '\\' not in line:   #test_base64(line): #re.search(pattern_64bit,line):
            print('detected base64')
            result['code'].append(line.strip())
        elif line.strip(): #if line contains anything other than whitespace
            if not result['description']:
                result['description'] = line #base case for the very first block
            else:
                print(idx, line)
                process_block(lines[idx+1:],description=line) #+1 to skip at the next line. prevents infinite recursion
    
    return result





def process_block_iterative(lines):
    results = []
    idx = 0
    
    while idx < len(lines):
        # print(len(lines) - idx)
        
        result = {
            'description': '',
            'properties': '',
            'tags': '',
            'code': []
        }
        
        while idx < len(lines):
            line = lines[idx]
            
            if line.startswith('properties:'):
                result['properties'] = line.split(':', 1)[1].strip()
            elif line.startswith('tags:'):
                result['tags'] = line.split(':', 1)[1].strip()
            elif len(line.strip()) == 69:
                # print('detected base64')
                result['code'].append(line.strip())
            elif line.strip():
                if not result['description']:
                    result['description'] = line.replace('\\n',' ')
                else:
                    # print(idx, line)
                    results.append(result)
                    lines = lines[idx:]
                    idx = 0
                    break
            
            idx += 1
        
        if idx == len(lines):
            results.append(result)
    
    return results


with open("GrappleMap_processed.txt", 'rb') as ff:
    db = ff.read().decode('utf-8')
    lines = db.split('\n')
    parsed = process_block_iterative(lines)


grapplemap = pd.DataFrame(parsed)
grapplemap.head()


#drop any rows with empty vals in the code column
grapplemap = grapplemap[grapplemap['code'].apply(len) != 0]
#one hot encode whether a row is of a move or a transition based on how many rows of code it has
grapplemap['is_position'] = grapplemap['code'].apply(lambda x: 1 if len(x) == 4 else 0)
grapplemap['is_transition'] = grapplemap['code'].apply(lambda x: 1 if len(x) > 4 else 0)

grapplemap.head()


def combine_every_four(input_list):
    # Check if the length is a multiple of 4
    if len(input_list) % 4 != 0:
        raise ValueError("Input list length must be a multiple of 4")
    
    # Use list comprehension to combine every 4 strings
    combined = [''.join(input_list[i:i+4]) for i in range(0, len(input_list), 4)]
    if len(combined) == 1:
        return combined[0]
    else:
        return combined

def extract_transition_positions(code_col, is_transition):
    if is_transition:
        return pd.Series({
            'start_position':code_col[0],
            'end_position':code_col[-1]})
    else:
        return pd.Series({
            'start_position':None,
            'end_position':None})

grapplemap['code'] = grapplemap['code'].apply(combine_every_four)




# np.unique(grapplemap['code'].apply(lambda x: len(x)) ,return_counts=True)
np.unique([len(i) for i in grapplemap['code']] ,return_counts=True)


transition_positions = grapplemap.apply(lambda row: extract_transition_positions(row['code'],row['is_transition']), axis=1)
grapplemap = pd.concat([grapplemap,transition_positions], axis=1)
grapplemap


# Separate positions and transitions
positions = grapplemap[grapplemap['is_position'] == 1]
transitions = grapplemap[grapplemap['is_transition'] == 1]

# Step 2: Create a set of unique position codes
position_codes = set(positions['code'])

# Step 3: Check for matches in start_position and end_position
matches = transitions[
    transitions['start_position'].isin(position_codes) |
    transitions['end_position'].isin(position_codes)
]

# Print the results
if not matches.empty:
    print("Found matches:")
    for _, row in matches.iterrows():
        if row['start_position'] in position_codes:
            print(f"Transition {row['description']} starts with a known position code")
        if row['end_position'] in position_codes:
            print(f"Transition {row['description']} ends with a known position code")
else:
    print("No matches found")

# You can also get the count of matches
print(f"\nTotal matches found: {len(matches)}")



grapplemap.to_csv('grapplemap_df.csv',index=False)



